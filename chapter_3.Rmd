---
title: <br><br><br> Understanding and Measuring Uncertainty
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
---

<style type="text/css">

#TOC {
margin-top: 100px;
}

.section h2{
padding-top: 150px;
}

.leftA{
float: left;
width: 100%;
font-weight: bold;
}

.rightA{
float:right;
width: 75%;
}

.leftB{
float: left;
width: 23%;
}

.headerBlue{
background-color:#008080; 
border-radius: 5px; 
padding: 20px;
width: 100%;
font-weight: bold;
float: centre;
colour: white;
}

.fullBoxBlue{
background-color:#AFEEEE; 
border-radius: 5px; 
padding: 20px;
width: 100%;
}

.halfBoxBlueLeft{
background-color:#AFEEEE; 
border-radius: 2px; 
padding: 20px;
width: 48%;
float: left;
}

.halfBoxBlueRight{
background-color:#AFEEEE; 
border-radius: 2px; 
padding: 20px;
width: 48%;
float: right;
}

</style>

<br>

<div class = "leftA">
Introduction
</div>

<div class = "rightA"> 
At this stage you should have considered where the uncertainties lie. You now will need to consider whether it is possible to quantify this uncertainty. 
</div>

<div class = "rightA">
This chapter presents some general approaches for quantifying and measuring the uncertainty in your analysis.
</div>


```{r fig.align="center", echo=FALSE, out.width='100%'}

knitr::include_graphics("images/Wheel.png")

```

<div style="clear: both;"></div>

## General approaches for quantifying uncertainty in an input parameter

<br>

<div class = "rightA"> 
We have highlighted ways to think about the size and distribution of uncertainty coming from specific sources.   We now bring this together into approaches that can be applied to any source of uncertainty.  In most cases, the approach to uncertainty quantification is limited by the data and time available to you.
</div>


<div class = "leftA">
Table 3.1: Sources of uncertainty
</div>

|  |  |
| ----------- | ------------------------------ |
|<b> Can you create a probability distribution? </b>| A probability distribution describes the probability of occurrences of different outcomes. Generally, there are two types of probability distribution; discrete distributions and continuous distributions. <br><br> Consider whether you have information about the underlying distribution of the parameter. Often data from other sources will be provided with confidence intervals (or standard errors, etc) that can be used to quantify uncertainty. Where such information is not provided, you may be able to approximate these with knowledge of the sample size and design. <br><br> Distributions can also be created using what you know about error from previous models.  Consider the performance of previous forecasts against outturn results . The distribution of previous errors can provide the uncertainty distribution for the current forecast. If no quantitative data on the underlying population is available, you may be able to elicit this information from experts . For example, the Delphi Method  can be used to ask a panel of experts to estimate the range of uncertainty and use the aggregated responses to produce a distribution.|
|<b> Can you create a range? </b> | A range is similar to a probability distribution, in that it considers the possible outcomes but does not consider the probability of each outcome occurring.  If there are data or resource limitations a range can be a simple way to illustrate the uncertainty in a parameter. <br><br> Historical data can be used to quantify a range. Consider how the parameter has changed over a suitable time period. The maximum and minimum values could provide a sensible range. When using historical data be aware that you will only be able to assess ‘business as usual’ uncertainty. If there are future shocks to the system this may fall outside your historic range. <br><br> For parameters that have been the subject of academic studies a literature review can be used to create a range. Consider why different studies may result in different outcomes, and which studies are the most suitable for what you are trying to measure. <br><br> If no quantitative data is available, consider whether there are relevant policy constraints that will limit your range. Judgement from experts can be also be used to create sensible ranges. |
|<b> If it is not possible to create a probability distribution or range, make a qualitative assessment </b> | In some situations, it is not possible to create a probability distribution or a range. In such cases, make a qualitative assessment of uncertainty.  This is still useful to analysts and customers to consider the magnitude of uncertainty. <br><br> You can make qualitative assessments yourself, and by using expert judgement. A simple approach is to Red Amber Green (RAG) rate the likelihood and impact of uncertainty in your parameters. This qualitative assessment should be considered when thinking about the analytical results. If data is categorised as highly uncertain and having a large impact on results, then final outputs will be subject to large uncertainty.|
|<b> Break-even analysis could help re-frame your assumption </b> | A further option to support decision makes is to use break-even analysis. This is useful to understand at which point a saving becomes a cost or possibly at which point you would take a different decision. <br><br> Some decision makers will be used to seeing a range around a central estimate. Break-even analysis works backwards – if we were to break-even what would the input be? This could help bring the policy alive and help assumption owners to really consider how realistic the assumption is. <br><br> Break-even analysis helps people understand how much the input has to change before you reach a break-even point so they can consider the probability of this occurring.| 

```{r fig.align="center", echo=FALSE, out.width='100%'}

knitr::include_graphics("images/squiggle.png")

```
 
<div style="clear: both;"></div>

## Common techniques for conducting uncertainty analysis

<br>


<div class = "rightA">
This section will cover common techniques for analysing uncertainty.
</div>

<br><br>

<div class = "headerBlue">
Monte Carlo Techniques
</div>

<br><br>

If all significant sources of uncertainty can be quantified, along with the correlations between them, then probabilistic methods can provide a full picture of the range of possible outcomes and the likelihood of each.

<br><br>

<div class = "fullBoxBlue">
<b>Outline:</b> 
<br><br>
The basic process for a Monte Carlo simulation is to:
<ol><li> Define a for each input showing the uncertainty in each. These can be simple distributions based on estimation (e.g. uniform, triangular) or more complex distributions based on data (e.g. normal, beta).</li>
<li> Define the correlations between these inputs </li>
<li> Randomly generate a value from each input distribution (accounting for correlations) </li>
<li> Calculate the outputs of the model deterministically </li>
<li> Repeat steps c) and d) many times </li>
<li> Analyse the distribution of the resulting outputs </li> </ol>
<br><br>
This should be repeated until the key outputs are stable and reproducible at the level of rounding that will be used when communicating the results </div>

<br><br>

<div class = "halfBoxBlueLeft">
<b>Advantages:</b> 
<br><br>
<ul><li>Produces a full probability profile of the range of possible outcomes and the likelihood of each – the gold standard in uncertainty analysis</li>
<li>Enables analysis of complex interactions between uncertainties within a model</li>
<li>Produces a visual representation of the range of possible outcomes, that may aid customer understanding</li>
<li>Can be used to assess the impact of  removing or reducing a source of uncertainty</li></ul>
</div>

<div class = "halfBoxBlueRight">
<b>Disadvantages:</b> 
<br><br>
<ul><li>Highly dependent on the accuracy of the distributions used</li>
<li>May require more resource than other techniques to build</li>
<li>Correlations can be difficult to define mathematically, and can give misleading results if not properly accounted for</li>
<li>Can be computationally expensive</li>
<li>Outputs may not be reproducible if insufficient iterations are used (effectively introducing further uncertainty to the model)</li></ul>
</div>

<br><br>


```{r fig.align="center", echo=FALSE, out.width='100%'}

knitr::include_graphics("images/Monte_carlo.png")

```

<br><br>

<div class = "fullBoxBlue">
<b>Example:</b> 
<br><br>
Can help assess overall uncertainty when you have uncertainty around many aspects of your model 
Assess uncertainty around a fund forecast 
Estimate the uncertainty around assumptions used in policy costings
An example of how MoJ use Monte Carlo analysis to assess uncertainty is provided here:  <b>Placeholder for link to Monte Carlo Template</b>
<br><br> &#64;Risk is an Excel add-in to analyse risk using Monte Carlo. An example of which is provided here:
<b>Placeholder for DfE &#64;Risk Example</b>

</div>

<div style="clear: both;"></div>

<br><br>

## Testing outputs as part of quality assurance

<br>

<div class = "leftB"> 
It is best practice to test the outputs of the analysis before using/presenting
</div>

<div class = "rightA"> 
After modelling uncertainty, you should always test the outputs of the analysis before sharing the results. This minimises the risk of errors in your analysis and helps you to understand the detailed outputs fully, including the level of the extreme or the most likely values.
</div>

<div class = "rightA"> 
Uncertainty analysis may produce ‘extreme outcomes’, so that implausible results or scenarios are given. These can be identified easily, through visualisation or filtering, and could indicate an issue with the setup conditions of your analysis.
</div>

<div class = "rightA"> 
Unusual results may also indicate a weakness in how you have used your chosen technique. For example, if using the Monte Carlo technique, there may be unknown correlation which hasn’t been accounted for, or you might use an inappropriate distribution for a parameter.
</div>

<div class = "leftB"> Unusual results may indicate a weakness in the use of the technique
</div>

<div class = "rightA"> 
One element to test in your analysis may be potential system shocks, such as a recession. Does your uncertainty analysis need to account for these? It is not always useful or practical to account for system shocks, depending on your analysis, and they may be better treated in a risk register. You should support your users by pointing out system shocks that are common or highly likely to impact.
</div>